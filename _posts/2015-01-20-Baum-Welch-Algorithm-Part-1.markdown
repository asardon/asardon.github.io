---
layout:     post
title:      "Baum Welch Algorithm"
subtitle:   "Part 1"
date:       2015-01-20 12:00:00
author:     "Aetienne Sardon"
header-img: "img/home-bg.jpg"
---

# Intro
<p>Today I would like to review the Baum-Welch algorithm, which is used to learn the parameters of a Hidden Markov Model (HMM). Recall that a HMM is defined by $\lambda=(S,V,A,B,\pi)$ where</p>
* $\mathcal{S}:=\{1,...,n\}$ are the possible hidden states that the random variable $S_t$ can assume at each time point $t$
* $\mathcal{O}:= \mathbb R$ is the codomain of possible observable values that the random variable $O_t$ can obtain (here we assume continuous values)
* $A\in \mathbb R^{n\times n}$ is the transition matrix such that $a\_{i,j}$ denotes the transition probability for switching from state $S_t=i$ to $S_{t+1}=j$
* $b\_1(o\_t),...,b\_n(o\_t)$ are the emission probabilities for observing $o\_t$ under each hidden state, i.e. $b\_{i}(o\_t)=\Pr(O\_t=o\_t\|S\_t=i)$. Here we assume the observations are generated by a mixture of Gaussians: $b\_{i}(o\_t):=\sum\_{l=1}^m w\_{i,l} \phi(o\_t\|\mu\_{i,l}, \sigma\_{i,l}^2)$ 
* $\pi:={\pi_1,...,\pi_n}$ are the initial state probabilities.

<p>The Baum-Welch algorithm is designed to find optimal parameters $\theta=(A,B,\pi)$ such that the probability of observing a certain sequence $\Pr(O_1=o_1,...,O_T=o_T|\theta)$ is maximized. Note that the Baum-Welch algorithm is a special case of the Expectation Maximization (EM) algorithm, which can be proven to converge towards a (local) maximum of the likelihood function.</p>

<p>Before we continue, let's introduce the following notation for convenience:</p>
$$ X_{i:j} := ( X_i, X_{i+1}, ..., X_j ) ,\quad i<j$$ 

<p>Furthermore, before we start with the Baum-Welch algorithm we need to recap on the forward-backward algorithm which we will use later on. As the name suggests, the forward-backward algorithm consists of two steps, i.e. the forward and backward procedure from which we obtain the so called forward $\alpha_i(t)$ and backward probabilities $\beta_i(t)$.</p>

# Forward Procedure
<p>In the forward procedure we determine the probability of observing the sequence $o_1,o_2,...,o_t$ and ending in the hidden state $S_t=i$ at time $t$. In other words:</p>

$$ \alpha_i(t) := \Pr(O_{1:t}=o_{1:t}, S_t=i | \theta) $$

<p>A closer examination of $\alpha_i(t)$ reveals that the forward probability is defined recursively:</p>
$$
\begin{eqnarray} 
\alpha_i(t) &=&  \Pr(o_{1:t}, S_t=i | \theta) \\
&=&  \Pr(o_{1:t-1}, o_t, S_t=i | \theta) \\
&=& \sum_{j=1}^{|\mathcal{S}|} \Pr(o_{1:t-1}, S_{t-1}=j, o_t, S_t=i | \theta) \\
&=& \sum_{j=1}^{|\mathcal{S}|} \Pr(o_t | o_{1:t-1}, S_{t-1}=j, S_t=i, \theta) \cdot \Pr(o_{1:t-1}, S_{t-1}=j, S_t=i | \theta) \\
&=& \sum_{j=1}^{|\mathcal{S}|} \Pr(o_t | o_{1:t-1}, S_{t-1}=j, S_t=i, \theta) \cdot \Pr(S_t=i | o_{1:t-1}, S_{t-1}=j, \theta) \cdot \Pr(o_{1:t-1}, S_{t-1}=j | \theta) \\
&=& \Pr(o_t | S_t=i, \theta) \sum_{j=1}^{|\mathcal{S}|} \Pr(S_t=i | S_{t-1}=j, \theta) \cdot \Pr(o_{1:t-1}, S_{t-1}=j | \theta) \\
&=& \Pr(o_t | S_t=i, \theta) \sum_{j=1}^{|\mathcal{S}|} \alpha_j(t-1) \Pr(S_t=i | S_{t-1}=j, \theta) \\
\end{eqnarray}$$
<p>Which finally leads to:</p>
$$\alpha_i(t) = b_{i}(o_t) \sum_{j=1}^{|\mathcal{S}|} \alpha_j(t-1) \cdot a_{j,i} $$
<p>where $\alpha_i(1)$ is defined as:</p>
$$\alpha_i(1) = \pi_i b_i(o_1) $$
<p>Note: In line 3 we add $S_{t-1}=j$ to the joint distribution and sum over all $j=1,...,n$ (marginalizing out) such that the equality remains valid. In line 4 and 5 we apply the chain rule and in line 6 we use the fact that $o_t$ is conditionally independent of $S_{t-1}$ given $S_t$.</p>


# Backward Procedure
<p>The backward procedure returns the probability of observing the sequence $o_{t+1},o_{t+2},...,o_T$ given that the HMM is in state $s_i$ at time $t$. The backward probability is defined as:</p>

$$ \beta_i(t) := \Pr(O_{t+1:T}=o_{t+1:T} | S_t=i, \theta) $$

<p>Analogous to the forward procedure, the backward probabilities are defined recursively:</p>

$$
\begin{eqnarray} 
\beta_i(t) &=& \Pr(o_{t+1:T} | S_t=i, \theta) \\
&=& \sum_{j=1}^{|\mathcal{S}|} \Pr(o_{t+1:T}, S_{t+1}=j| S_t=i, \theta) \\
&=& \sum_{j=1}^{|\mathcal{S}|} \Pr(o_{t+1:T} | S_{t+1}=j, \theta) \cdot \Pr(S_{t+1}=j | S_t=i, \theta) \\
&=& \sum_{j=1}^{|\mathcal{S}|} \Pr(o_{t+1:T} | S_{t+1}=j, \theta) \cdot a_{i,j} \\
&=& \sum_{j=1}^{|\mathcal{S}|} \Pr(o_{t+1} | S_{t+1}=j, o_{t+2:T}, \theta)
\cdot \Pr(o_{t+2:T} | S_{t+1}=j, \theta) 
\cdot a_{i,j} \\
&=& \sum_{j=1}^{|\mathcal{S}|} a_{i,j} \cdot \Pr(o_{t+1} | S_{t+1}=j, \theta) \cdot  \Pr(o_{t+2:T} | S_{t+1}=j, \theta)
\end{eqnarray}$$

<p>Finally, this leads to:</p>
$$\beta_i(t) = \sum_{j=1}^{|\mathcal{S}|} a_{i,j} \cdot b_{j}(o_{t+1}) \cdot \beta_j(t+1)$$

<p>where $\beta_i(0)$ is defined as:</p>
$$\beta_i(T)=1$$

<p>Note: In line 2 we add $S_{t+1}=j$ to the joint distribution and sum over all $j=1,...,n$ (marginalizing out) such that the equality remains valid. In line 3 we use the fact that $o_{t+1:T}$ is conditionally independent of $S_t$ given $S_{t+1}$. In line 5 we use the chain rule. In line 6 we rearrange and drop $o_{t+2:T}$ out of the condition because of the independence of observations.</p>

# Finding HMM Parameters
<p>Ultimately, we're interested in finding the maximum likelihood estimate (MLE) $\theta^{*}$, i.e.</p>
$$\theta^{*}=\operatorname*{arg\,max}_{\theta} \mathcal{L}(\theta|O_{1:T},S_{1:T})$$

<p>where $\mathcal{L}(\theta|o_{1:T},s_{1:T})=\Pr(o_{1:T},s_{1:T}|\theta)$ is the likelihood function. However, since the state sequence $s_{1:T}$ is unobservable we marginalize the hidden states out and thus maximize the marginal likelihood:</p>
$$\theta^{*}=\operatorname*{arg\,max}_{\theta} \sum_{s\in\mathcal{S}^T}\Pr(o_{1:T},s_{1:T}|\theta)$$

<p>Unfortunately, as $|\mathcal{S}|$ and $T$ become larger MLE becomes clearly intractable because we would have to iterate over all possible state paths (which grow exponentially) to find the optimal parameter set $\theta^{*}$. This is where the EM algorithm comes into play. The EM algorithm allows us to obtain the MLE by iteratively repeating the following steps until convergence (increasing log-likelihood values are guaranteed):</p>

1. Determine the "$Q$-Function":
$$Q(\theta,\theta^{(k)}):=\mathbb{E}[ \log \mathcal{L}(\theta|o_{1:T},s_{1:T})|o_{1:T}, \theta^{(k)}]$$
2. Find the optimal parameter $\theta^{(k+1)}$ that maximizes $Q$: 
$$\theta^{(k+1)}:=\operatorname*{arg\,max}_{\theta} Q(\theta,\theta^{(k)})$$

## Determine the Q-Function
<p>Before we can determine $Q(\cdot)$ we need to find out what the likelihood function looks like:</p>
$$
\begin{eqnarray} 
\mathcal{L}(\theta|o_{1:T},s_{1:T})&=&\Pr(o_{1:T},s_{1:T}|\theta) \\
&=& \Pr(s_1|\theta) \cdot \Pr(o_1|s_1,\theta) \cdot \prod_{t=1}^{T-1} \Pr(s_{t+1}|s_t) \cdot \Pr(o_{t+1}|s_{t+1},\theta) \\
&=& \pi_{i} \cdot b_{i}(o_1) \cdot \prod_{t=1}^{T-1} a_{i,j} \cdot b_{i}(o_{t+1})
\end{eqnarray}$$

<p>Hence, the log-likelihood is defined by:</p>
$$
\log \mathcal{L}(\theta|o_{1:T},s_{1:T})= \log \pi_{i} + \log b_{i}(o_1) + \sum_{t=1}^{T-1} \log a_{i,j} + \sum_{t=2}^{T} \log b_{i}(o_{t})
$$

<p>Next, we determine the expectation of the log-likelihood function conditional on the old parameter $\theta^{(k)}$:</p>
$$
\begin{eqnarray} 
Q(\theta,\theta^{(k)})&=&\mathbb{E} [ \log \mathcal{L}(\theta|o_{1:T},s_{1:T}) | o_{1:T}, \theta^{(k)}] \\
&=& \sum_{s\in \mathcal{S}} \log \mathcal{L}(\theta|o_{1:T},s_{1:T}) \cdot \Pr(o_{1:T}, s_{1:T}|\theta^{(k)}) \\
&=&  \sum_{i=1}^n \log \pi_{i} \cdot \Pr(S_1=i,o_{1}|\theta^{(k)}) 
+ \sum_{i=1}^n \sum_{j=1}^n  \sum_{t=1}^{T-1} \log a_{i,j} \cdot \Pr(S_{t}=i, S_{t+1}=j, o_{1:T}| \theta^{(k)}) 
+ \sum_{i=1}^n \sum_{t=1}^{T} \log b_{i}(o_{t}) \cdot \Pr(S_{t}=i,o_{1:T} | \theta^{(k)}) \\
&=&  \sum_{i=1}^n \log \pi_{i} \cdot \Pr(S_1=i,o_{1}|\theta^{(k)}) 
+ \sum_{i=1}^n \sum_{j=1}^n  \sum_{t=1}^{T-1} \log a_{i,j} \cdot \Pr(S_{t}=i, S_{t+1}=j, o_{1:T}| \theta^{(k)}) 
+ \sum_{i=1}^n \sum_{t=1}^{T} \log (\sum_{l=1}^{m} w_{i,l} \phi(o_t|\mu_{i,l}, \sigma_{i,l}^2) ) \cdot \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) 
\end{eqnarray}
$$


## Maximization of the Q-Function
<p>Now that we have an explicit form for $Q(\cdot)$ we turn to the second step of the EM algorithm, which is to find a new parameter $\theta^{(k+1)}$ that maximizes $Q(\cdot)$:</p>
$$
\theta^{(k+1)}:=\operatorname*{arg\,max}_{\theta} Q(\theta,\theta^{(k)})
$$
<p>However, we need to specify constraints for our parameters $\pi, a_{i,j}, w_{i,m}$ because otherwise we would maximize $Q(\cdot)$ by simply increasing the parameter values up to infinity. We don't want that because $\pi, a_{i,j}, w_{i,m}$ represent probabilities/weights, thus we impose the following constraints:</p>

1. $\sum\_{i=1}^n \pi\_i = 1$
2. $\sum\_{j=1}^n a\_{i,j} =1 \quad , \forall i=1,...,n$
3. $\sum\_{l=1}^m w\_{i,l}=1 \quad, \forall i=1,...,n$

<p>Maximization under constraints can be solved using Lagrange multipliers. Let's define the Lagrangian $\Lambda(\theta, \theta^{(k)})$ as:</p>
$$
\Lambda(\theta, \theta^{(k)}) = Q(\theta,\theta^{(k)}) 
-\lambda_{\pi} (\sum_{i=1}^n \pi_i - 1)
-\sum_{i=1}^n \lambda_{A_i} (\sum_{j=1}^n a_{i,j} - 1)
-\sum_{i=1}^n \lambda_{w_i} (\sum_{l=1}^m w_{i,l}-1)
$$
<p>Note that we can find the optimal parameters $\pi, a_{i,j}, w_{i,m}$ independently from one another.</p>

### Initial State Probabilities
<p>First, we take the partial derivative of $\Lambda(\theta, \theta^{(k)})$ with respect to $\pi_l$ with $l=1,...n$ and set it to zero:</p>
$$
\begin{eqnarray} 
0 &\overset{!}{=}& \frac{\partial}{\partial \pi_l}  \Lambda(\theta, \theta^{(k)}) \\
&=& \frac{\partial}{\partial \pi_l}Q(\theta,\theta^{(k)}) 
-\frac{\partial}{\partial \pi_l}\lambda_{\pi} (\sum_{i=1}^n \pi_i - 1) \\
&=& \frac{\partial}{\partial \pi_l} \sum_{i=1}^n \log \pi_{i} \cdot \Pr(S_1=i,o_{1}|\theta^{(k)}) - \lambda_{\pi} \\
&=& \frac{\Pr(S_1=l,o_{1}|\theta^{(k)}) }{\pi_{l}} - \lambda_{\pi}
\end{eqnarray}
$$

<p>Solving for $\lambda_{\pi}$ and marginalizing $S_1$ out gives us:</p>
$$
\begin{eqnarray} 
\lambda_{\pi} &=& \frac{\Pr(S_1=l,o_{1}|\theta^{(k)}) }{ \Pr(S_1=l|\theta^{(k)})  } \\
&=& \frac{\sum_{l=1}^n \Pr(S_1=l, o_{1}|\theta^{(k)})  }{\sum_{l=1}^n \Pr(S_1=l|\theta^{(k)})  } \\
&=& \frac{\Pr(o_{1}|\theta^{(k)})  }{1}
\end{eqnarray}
$$

<p>Plugging our result $\lambda_{\pi}=\Pr(o_{1}|\theta^{(k)})$ into the partial derivative $\frac{\partial}{\partial \pi_k}  \Lambda(\theta, \theta^{(k)})$ and solving for $\pi_l$ results in:</p>
$$
\begin{eqnarray} 
\pi_{l} &=& \frac{\Pr(S_1=l,o_{1}|\theta^{(k)}) }{\lambda_{\pi}} \\
&=& \frac{\Pr(S_1=l,o_{1}|\theta^{(k)}) }{\Pr(o_{1}|\theta^{(k)})} \\
&=& \Pr(S_1=l|o_{1},\theta^{(k)})
\end{eqnarray}
$$

### Transition Probabilities
 <p>Now, we take the partial derivative of $\Lambda(\theta, \theta^{(k)})$ with respect to $a_{h,l}$:</p>
$$
\begin{eqnarray} 
0 &\overset{!}{=}& \frac{\partial}{\partial a_{h,l}}  \Lambda(\theta, \theta^{(k)}) \\
&=& \frac{\partial}{\partial a_{h,l}} Q(\theta,\theta^{(k)}) 
-\frac{\partial}{\partial a_{h,l}} \sum_{i=1}^n \lambda_{A_i} (\sum_{j=1}^n a_{i,j} - 1) \\
&=& \frac{\partial}{\partial a_{h,l}} \sum_{i=1}^n \sum_{j=1}^n  \sum_{t=1}^{T-1} \log a_{i,j} \cdot \Pr(S_{t}=i, S_{t+1}=j, o_{1:T}| \theta^{(k)}) 
- \lambda_{A_h} \\
&=& \sum_{t=1}^{T-1} \frac{ \Pr(S_{t}=h, S_{t+1}=l, o_{1:T}| \theta^{(k)}) }{ a_{h,l} } 
- \lambda_{A_h}
\end{eqnarray}
$$ 

<p>Solving for $\lambda_{A_h}$ and marginalizing $S_{t+1}=l$ out:</p>
$$
\begin{eqnarray} 
\lambda_{A_h} &=& \sum_{t=1}^{T-1} \frac{ \sum_{l=1}^{n} \Pr(S_{t}=h, S_{t+1}=l, o_{1:T}| \theta^{(k)}) }{ \sum_{l=1}^{n} \Pr(S_{t+1}=l| S_{t}=h) } \\
&=& \sum_{t=1}^{T-1} \frac{\Pr(S_{t}=h, o_{1:T}| \theta^{(k)}) }{ 1 } 
\end{eqnarray}
$$

<p>Plugging $\lambda_{A_h}$ into the partial derivative $\frac{\partial}{\partial a_{h,l}}\Lambda(\theta, \theta^{(k)})$ leads to:</p>
$$
\begin{eqnarray} 
a_{h,l} &=& \sum_{t=1}^{T-1} \frac{ \Pr(S_{t}=h, S_{t+1}=l, o_{1:T}| \theta^{(k)}) }{ \lambda_{A_h} }  \\
&=& \sum_{t=1}^{T-1} \frac{ \Pr(S_{t}=h, S_{t+1}=l, o_{1:T}| \theta^{(k)}) }{ \Pr(S_{t}=h, o_{1:T}| \theta^{(k)})  } 
\end{eqnarray}
$$


### Gaussian Mixture Parameters
 <p>For the Gaussian Mixture model we need to estimate for each hidden state $i=1,...,n$ the weights $w_{i,l}$ as well as the distribution parameters $\mu_{i,l}, \sigma_{i,l}^2$ for each mixture component $l=1,...,m$. Let's first find the optimal weights by taking the partial derivative of $\Lambda(\theta, \theta^{(k)})$ with respect to $w_{i,l}$:</p>
$$
\begin{eqnarray} 
0 &\overset{!}{=}& \frac{\partial}{\partial w_{i,l}}  \Lambda(\theta, \theta^{(k)}) \\
&=& \frac{\partial}{\partial w_{i,l}} Q(\theta,\theta^{(k)}) 
-\frac{\partial}{\partial w_{i,l}} \sum_{i=1}^n \lambda_{w_i} (\sum_{l=1}^m w_{i,l} - 1) \\
&=& \frac{\partial}{\partial w_{i,l}}( \sum_{i=1}^n \sum_{t=1}^T log( \sum_{l=1}^m w_{i,l} \phi(o_t|\mu_{i,l}, \sigma_{i,l}^2) ) \cdot \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)})  ) - \lambda_{w_i} \\
&=& \sum_{t=1}^T \frac{\phi(o_t|\mu_{i,l}, \sigma_{i,l}^2)}{w_{i,l} \phi(o_t|\mu_{i,l}, \sigma_{i,l}^2)} \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)})  - \lambda_{w_i} \\
w_{i,l} \lambda_{w_i} &=& \sum_{t=1}^T \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) \\
\lambda_{w,i} &=& \sum_{t=1}^T \Pr(S_{t}=i,o_{1:T} | \theta^{(k)}) 
\end{eqnarray} 
$$ 

<p>In the last line we marginalize the mixture variable $l$ out. Plugging our result for $\lambda_{w,i}$ back into the partial derivative equation finally leads to:</p>

$$
\begin{eqnarray} 
w_{i,l} &=& \frac{ \sum_{t=1}^T \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)})  }{ \sum_{t=1}^T \Pr(S_{t}=i,o_{1:T} | \theta^{(k)})  } \\
&=& \frac{ \sum_{t=1}^T \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)})  }{ \sum_{t=1}^T \sum_{l=1}^m \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)})  } \\
&=& \frac{ \sum_{t=1}^T \Pr(S_{t}=i, l | o_{1:T} \theta^{(k)}) \Pr(o_{1:T})  }{ \sum_{t=1}^T \sum_{l=1}^m \Pr(S_{t}=i,l | o_{1:T}, \theta^{(k)}) \Pr(o_{1:T}) } \\
&=& \frac{ \sum_{t=1}^T \Pr(S_{t}=i, l | o_{1:T} \theta^{(k)})   }{ \sum_{t=1}^T \sum_{l=1}^m \Pr(S_{t}=i,l | o_{1:T}, \theta^{(k)}) }
\end{eqnarray} 
$$ 

<p>And now we turn to $\mu_{i,l}$:</p>
$$
\begin{eqnarray} 
0 &\overset{!}{=}& \frac{\partial}{\partial \mu_{i,l}}  \Lambda(\theta, \theta^{(k)}) \\
&=& \frac{\partial}{\partial \mu_{i,l}} Q(\theta,\theta^{(k)}) 
\\
&=& \frac{\partial}{\partial \mu_{i,l}}( \sum_{i=1}^n \sum_{t=1}^T log( \sum_{l=1}^m w_{i,l} \phi(o_t|\mu_{i,l}, \sigma_{i,l}^2) ) \cdot \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)})  ) \\
&=& \frac{\partial}{\partial \mu_{i,l}}( \sum_{i=1}^n \sum_{t=1}^T \prod_{l=1}^m log( w_{i,l}) + log( \phi(o_t|\mu_{i,l}, \sigma_{i,l}^2) ) \cdot \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)})  )  \\
&=& \sum_{t=1}^T \frac{\partial}{\partial \mu_{i,l}} log( \phi(o_t|\mu_{i,l}, \sigma_{i,l}^2) ) \cdot \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) \\
&=& \sum_{t=1}^T \frac{\partial}{\partial \mu_{i,l}} ( -\frac{1}{2} log( 2 \pi \sigma_{i,l}^2) + \frac{(o_t-\mu_{i,l})^2}{2\sigma_{i,l}^2} ) \cdot \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) \\
&=& \sum_{t=1}^T -2\frac{o_t- \mu_{i,l}}{2\sigma_{i,l}^2} \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) 
\end{eqnarray} 
$$
<p>Rearranging results in:</p>
$$
\begin{eqnarray} 
\mu_{i,l} \sum_{t=1}^T \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) &=& \sum_{t=1}^T o_t \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) \\
\mu_{i,l} &=& \frac{\sum_{t=1}^T o_t \Pr(S_{t}=i, l | o_{1:T},  \theta^{(k)}) \Pr(o_{1:T})}{\sum_{t=1}^T \Pr(S_{t}=i, l | o_{1:T}, \theta^{(k)}) \Pr(o_{1:T} )} \\
&=& \frac{\sum_{t=1}^T o_t \Pr(S_{t}=i, l | o_{1:T},  \theta^{(k)}) }{\sum_{t=1}^T \Pr(S_{t}=i, l | o_{1:T}, \theta^{(k)})} 
\end{eqnarray} 
$$ 

<p>Analogously, we obtain the optimal $\sigma_{i,l}^2$ parameter by:</p>
$$
\begin{eqnarray} 
0 &\overset{!}{=}& \frac{\partial}{\partial \sigma_{i,l}}  \Lambda(\theta, \theta^{(k)}) \\
&=& \frac{\partial}{\partial \mu_{i,l}} Q(\theta,\theta^{(k)}) \\
&=& \sum_{t=1}^T \frac{\partial}{\partial \sigma_{i,l}} ( -\frac{1}{2} log( 2 \pi \sigma_{i,l}^2) + \frac{(o_t-\mu_{i,l})^2}{2\sigma_{i,l}^2} ) \cdot \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) \\
&=& \sum_{t=1}^T (-\frac{1}{\sigma_{i,l}} - \frac{1}{\sigma_{i,l}^2}(o_t-\mu_{i,l})^2) \Pr(S_{t}=i,o_{1:T}, l | \theta^{(k)}) 
\end{eqnarray} 
$$
<p>Thus we get:</p>
$$
\begin{eqnarray} 
\sigma_{i,l}^2 &=& \frac{\sum_{t=1}^T (o_t-\mu_{i,l})^2 \Pr(S_{t}=i, l | o_{1:T},\theta^{(k)})}{\sum_{t=1}^T \Pr(S_{t}=i, l | o_{1:T},\theta^{(k)})}
\end{eqnarray} 
$$

### Parameter Updates
<p>We can define some 'helper' variables to make the parameter updates easier:</p>
$$
\begin{eqnarray} 
\gamma_i(t) &:=& \Pr(S_t=i|o_{1:T}, \theta^{(k)}) \\
&=& \frac{ \alpha_i(t) \cdot \beta_i(t) }{ \sum_{i=1}^n \alpha_i(t) \cdot \beta_i(t) }  \\
\gamma_{i,l}(t) &:=& \Pr(S_t=i, l|o_{1:T}, \theta^{(k)}) \\
&=& \gamma_i(t) \frac{ w_{i,l} b_{i,l}(o_t) }{ \sum_{l=1}^m b_{i,l}(o_t)  }  \\
\xi_{i,j}(t) &:=& \Pr(S_{t+1}=i, S_t=j | o_{1:T}) \\
&=& \frac{ \alpha_i(t)  a_{i,j} b_{j}(o_{t+1}) \beta_j(t+1)   }{ \sum_{i=1}^n \sum_{j=1}^n  \alpha_i(t)  a_{i,j} b_{j}(o_{t+1}) \beta_j(t+1)  } 
\end{eqnarray} 
$$

<p>Plugging these helper variables into our previously derived parameter update equations finally leads to:</p>

$$
\begin{eqnarray} 
\pi_{i} &=& \gamma_i(1) \\
a_{i,j} &=& \frac{ \sum_{t=1}^{T-1} \xi_{i,j}(t) }{ \sum_{t=1}^{T-1} \gamma_i(t) } \\
w_{i,l} &=&  \frac{ \sum_{t=1}^{T} \gamma_{i,l}(t) }{ \sum_{t=1}^{T} \gamma_i(t) } \\
\mu_{i,l} &=&  \frac{ \sum_{t=1}^{T} \gamma_{i,l}(t) o_t }{ \sum_{t=1}^{T} \gamma_{i,l}(t) } \\
\sigma_{i,l}^2 &=&  \frac{ \sum_{t=1}^{T} \gamma_{i,l}(t) (o_t - \mu_{i,l} ) ^2 }{ \sum_{t=1}^{T} \gamma_{i,l}(t) } \\
\end{eqnarray}
$$

Puh, that's it for now. In the next part we will try to implement our results into Python code.